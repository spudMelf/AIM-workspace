{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not enabled\n"
     ]
    }
   ],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    print(\"GPU is not enabled\")\n",
    "else:\n",
    "    print(\"GPU is enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/eamon/Desktop/AIM'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/Users/eamon/Desktop/AIM/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepfake_dataloader import DeepfakeDataset \n",
    "\n",
    "dataset = DeepfakeDataset(directory_path='../release_in_the_wild/', length=1250, transform=transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize the image to the required input size of your CNN\n",
    "    transforms.ToTensor(),           # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of each instance is torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(f'The shape of each instance is {dataset[0][0].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label of the first instance is tensor([1])\n"
     ]
    }
   ],
   "source": [
    "print(f'The label of the first instance is {dataset[0][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [.8, .2])\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the train_dataloader is 1000\n",
      "The size of the test_dataloader is 250\n"
     ]
    }
   ],
   "source": [
    "print(f'The size of the train_dataloader is {len(dataset) * .8:.0f}')\n",
    "print(f'The size of the test_dataloader is {len(dataset) * .2:.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CustomResNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomResNet, self).__init__()\n",
    "        self.resnet = models.resnet18(weights=None)\n",
    "        num_ftrs = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "model = CustomResNet(num_classes=2)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        inputs, labels = data\n",
    "        labels = labels.squeeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # Print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test dataset: 96 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()  \n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  \n",
    "    for data in test_dataloader:\n",
    "        inputs, labels = data\n",
    "        labels = labels.squeeze(1)  \n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)  \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test dataset: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy looked way too good so I had to ask chatgpt to help find EER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.79836905e-01 9.99817073e-01 3.41197327e-02 9.99971271e-01\n",
      " 6.89652516e-03 2.91959226e-01 9.87306356e-01 9.98737276e-01\n",
      " 5.37002325e-01 1.07502136e-02 9.27562546e-03 2.90082037e-01\n",
      " 9.93652225e-01 1.45574128e-02 9.70215678e-01 4.21678126e-02\n",
      " 1.48974890e-02 4.21220378e-04 1.00150276e-02 9.30585563e-01\n",
      " 1.85425917e-03 7.23335310e-04 8.71605182e-04 9.97721255e-01\n",
      " 9.94293988e-01 9.99912858e-01 7.31554767e-03 7.45700393e-03\n",
      " 2.06408463e-03 9.84534979e-01 1.72656099e-03 3.66550148e-03\n",
      " 1.49135347e-02 9.99938250e-01 1.54276267e-01 5.69233613e-04\n",
      " 9.99714315e-01 4.34447732e-03 9.95333374e-01 3.76384170e-03\n",
      " 2.37905756e-02 7.42593734e-03 4.20900574e-03 3.20174336e-01\n",
      " 2.17483169e-03 4.39920649e-03 1.85840186e-02 1.12543325e-03\n",
      " 1.52133405e-02 1.45362355e-02 1.16604771e-02 1.07079349e-01\n",
      " 1.34519646e-02 9.96878982e-01 9.72107111e-04 5.37815364e-03\n",
      " 5.26700556e-01 4.14094393e-04 1.27599929e-02 4.61189657e-01\n",
      " 9.60543931e-01 9.99980927e-01 9.99509096e-01 2.48742639e-03\n",
      " 1.50615862e-03 9.96932864e-01 1.85458135e-04 6.84055639e-03\n",
      " 2.91587348e-04 9.99984503e-01 9.99749243e-01 1.68897714e-02\n",
      " 9.99791324e-01 1.01888133e-03 4.53400552e-01 2.28786096e-03\n",
      " 3.62461014e-03 9.98248696e-01 8.09537654e-04 3.68877454e-03\n",
      " 9.99885082e-01 9.45794024e-03 1.47498161e-01 3.02844518e-03\n",
      " 3.79055017e-03 2.89116963e-03 1.34527246e-02 9.98625875e-01\n",
      " 8.74901004e-03 1.16348080e-02 9.97882307e-01 5.42666018e-03\n",
      " 9.69527185e-01 1.81219541e-02 1.19006597e-02 5.85213363e-01\n",
      " 1.56879961e-03 9.99995589e-01 6.72088529e-04 7.34944409e-03\n",
      " 2.48842314e-02 9.92978156e-01 8.71720910e-03 9.25752968e-02\n",
      " 1.10656880e-02 2.21153256e-03 1.56958234e-02 2.73538772e-02\n",
      " 1.07291376e-03 5.96656352e-02 9.98707056e-01 1.16020702e-01\n",
      " 6.07679598e-03 8.16223386e-04 1.55188432e-02 8.38887718e-05\n",
      " 9.88803566e-01 9.98909950e-01 2.66597024e-03 9.90430534e-01\n",
      " 4.95281219e-02 7.47669768e-03 1.23346574e-04 1.66444480e-03\n",
      " 9.99770701e-01 1.15922904e-02 9.99980092e-01 9.98098075e-01\n",
      " 9.98727739e-01 2.28183018e-03 3.65758359e-01 9.98928726e-01\n",
      " 3.42401699e-03 1.69469621e-02 5.59342676e-04 1.96774933e-03\n",
      " 9.95933115e-01 2.60954932e-03 9.99303818e-01 9.99967456e-01\n",
      " 5.09975653e-04 9.99878287e-01 9.96120512e-01 2.34089512e-03\n",
      " 5.03412122e-03 4.39319015e-02 7.99076073e-03 4.28726338e-03\n",
      " 8.96755695e-01 2.95410259e-03 8.61771498e-03 6.70431741e-03\n",
      " 2.58469004e-02 1.32486485e-02 9.88258362e-01 9.99995589e-01\n",
      " 2.23325612e-03 1.67551707e-03 9.99979496e-01 8.79910290e-01\n",
      " 2.57929438e-04 3.41784419e-03 1.80016365e-02 8.19624285e-04\n",
      " 2.18336773e-03 1.44562835e-03 9.30895971e-04 1.23714805e-02\n",
      " 6.41913479e-03 2.55478197e-03 3.12577397e-01 3.47530964e-04\n",
      " 9.99917746e-01 1.11199968e-01 9.99154687e-01 2.01391160e-01\n",
      " 7.61315366e-03 2.00204104e-02 1.80723052e-03 9.66455996e-01\n",
      " 3.98588134e-04 9.99702871e-01 1.30927889e-04 3.41661535e-02\n",
      " 1.73160229e-02 1.21853221e-03 8.36005569e-01 6.20774105e-02\n",
      " 9.99337375e-01 9.88709867e-01 9.99142051e-01 1.22847604e-02\n",
      " 9.99522209e-01 3.54610058e-03 3.13586876e-04 9.99985456e-01\n",
      " 1.43171549e-01 1.53052923e-03 9.99538541e-01 9.95019171e-03\n",
      " 2.59070098e-02 3.10734776e-03 9.95344222e-01 1.62893979e-04\n",
      " 9.96281326e-01 9.98518407e-01 9.98298943e-01 9.78053808e-01\n",
      " 7.69334985e-03 9.67185736e-01 3.20499600e-03 9.42605555e-01\n",
      " 7.00170593e-03 4.93081112e-04 3.36063690e-02 1.56232563e-03\n",
      " 7.77249753e-01 9.38990295e-01 9.66004610e-01 2.69288290e-03\n",
      " 9.53621745e-01 8.06154497e-03 9.83040407e-03 6.95691351e-03\n",
      " 9.99876022e-01 6.80665439e-03 1.86272874e-03 6.81239506e-03\n",
      " 3.27090994e-02 1.66059043e-02 7.04065263e-01 9.98233318e-01\n",
      " 5.77182584e-02 1.53306806e-02 3.52916010e-02 2.27831248e-02\n",
      " 9.90666807e-01 4.13103821e-03 1.48741718e-04 9.07869544e-03]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Initialize an empty list to store the scores\n",
    "scores = []\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient calculation for evaluation\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        inputs, _ = data  # Assuming you don't need labels for this\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Apply softmax to convert logits to probabilities\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        \n",
    "        # Extract the probability of the positive class (class 1)\n",
    "        positive_scores = probabilities[:, 1]\n",
    "        \n",
    "        # Convert to numpy array and append to the scores list\n",
    "        scores.extend(positive_scores.cpu().numpy())\n",
    "\n",
    "# Convert scores list to numpy array\n",
    "scores = np.array(scores)\n",
    "\n",
    "# Now you have the array of confidence scores from the model\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1 1 0 1 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 0 1 0\n",
      " 0 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 0 1 0\n",
      " 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize an empty list to store the true labels\n",
    "true_labels = []\n",
    "\n",
    "# Iterate over the test dataset using the test_dataloader\n",
    "for data in test_dataloader:\n",
    "    _, labels = data  # Assuming labels are provided in the second element of the tuple\n",
    "    labels = labels.squeeze(1)  # Remove extra dimension if present\n",
    "    true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert true labels list to numpy array\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "# Now you have the true labels from the test dataset\n",
    "print(true_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5798369  0.9998171  0.03411973 0.9999713  0.00689653 0.29195923\n",
      " 0.98730636]\n",
      "[1 1 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(scores[:7])\n",
    "print(true_labels[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal Error Rate (EER): 4.98%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Assuming you have the scores and true labels\n",
    "# scores: array of confidence scores from your model\n",
    "# labels: true labels (0 or 1)\n",
    "\n",
    "# Compute the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(true_labels, scores)\n",
    "\n",
    "# Calculate the FAR and FRR\n",
    "far = 1 - tpr\n",
    "frr = fpr\n",
    "\n",
    "# Find the point where FAR equals FRR\n",
    "eer_threshold = thresholds[np.nanargmin(np.abs(far - frr))]\n",
    "eer = (far[np.nanargmin(np.abs(far - frr))] + frr[np.nanargmin(np.abs(far - frr))]) / 2\n",
    "\n",
    "print(\"Equal Error Rate (EER): {:.2f}%\".format(eer * 100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
